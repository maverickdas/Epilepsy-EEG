{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "\n",
    "\n",
    "from keras.layers import MaxPooling1D, Dense, Dropout, Flatten, Input, Conv1D, LeakyReLU, BatchNormalization, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_path = os.getcwd()\n",
    "# curr_path\n",
    "# lossfn = LeakyReLU(alpha=0.02)\n",
    "lossfn = 'relu'\n",
    "BATCH = False\n",
    "EPOCHS = 500\n",
    "DROPRATE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dict = {\"O\":[0, 0,0,1],\"F\":[0, 0,1,0], 'S':[0, 1,0,0], \"N\":[1, 0,0,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(fold,label):\n",
    "    fold_arr = []\n",
    "    labels_arr = []\n",
    "    files = []\n",
    "    for f in os.listdir(fold):\n",
    "        files.append(osp.join(fold, f))\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        lines = []\n",
    "        with open(f, 'r') as fw:\n",
    "            for i, line in enumerate(fw):\n",
    "                lines.append(int(line.split()[0]))\n",
    "        lines_arr = np.array(lines)\n",
    "        lines_arr=(lines_arr-np.mean(lines_arr))/np.var(lines_arr)\n",
    "        fold_arr.append(lines_arr)\n",
    "        labels_arr.append(label)\n",
    "    return fold_arr,labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_len = len(fold_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_list = []\n",
    "train_X = []\n",
    "train_Y = []\n",
    "for key,val in fold_dict.items():\n",
    "    x,y = extract(key,val)\n",
    "    train_X.extend(x)\n",
    "    train_Y.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X),len(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lay = Input((4097,1))\n",
    "\n",
    "\n",
    "l1 = Conv1D(4, kernel_size = 6, strides=1, padding = 'same',activation = lossfn)(in_lay)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(4, kernel_size = 5, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(10, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(10, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(15, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(15, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "    \n",
    "l1 = Conv1D(20, kernel_size = 3, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "flat = Flatten()(ml1)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(50)(flat)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(20)(flat)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(out_len)(flat)\n",
    "\n",
    "flat = Softmax()(flat)\n",
    "\n",
    "model=Model(inputs = [in_lay], outputs = [flat])\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('retina_result')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                   factor=0.998, \n",
    "                                   patience=10, \n",
    "                                   verbose=1, \n",
    "                                   mode='auto', \n",
    "                                   min_delta=0.0001, \n",
    "                                   cooldown=5, \n",
    "                                   min_lr=0.0000001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=150)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.array(train_X)\n",
    "LABEL = np.array(train_Y)\n",
    "\n",
    "DATA = DATA.reshape((DATA.shape[0], DATA.shape[1], 1))\n",
    "# LABEL = LABEL.reshape((LABEL.shape[0], LABEL.shape[1], 1))\n",
    "\n",
    "# DATA.shape, LABEL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360 samples, validate on 40 samples\n",
      "Epoch 1/500\n",
      "360/360 [==============================] - 3s 8ms/step - loss: 1.3866 - accuracy: 0.2556 - val_loss: 1.4027 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.40269, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 2/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 1.3847 - accuracy: 0.2806 - val_loss: 1.4200 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.40269\n",
      "Epoch 3/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 1.3812 - accuracy: 0.3222 - val_loss: 1.4419 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.40269\n",
      "Epoch 4/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 1.3777 - accuracy: 0.3500 - val_loss: 1.4677 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.40269\n",
      "Epoch 5/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 1.3773 - accuracy: 0.2972 - val_loss: 1.4958 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.40269\n",
      "Epoch 6/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 1.3753 - accuracy: 0.3056 - val_loss: 1.5275 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.40269\n",
      "Epoch 7/500\n",
      "360/360 [==============================] - 0s 207us/step - loss: 1.3650 - accuracy: 0.3167 - val_loss: 1.5683 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.40269\n",
      "Epoch 8/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 1.3619 - accuracy: 0.3278 - val_loss: 1.6177 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.40269\n",
      "Epoch 9/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 1.3558 - accuracy: 0.3667 - val_loss: 1.6723 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.40269\n",
      "Epoch 10/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 1.3547 - accuracy: 0.3556 - val_loss: 1.7276 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.40269\n",
      "Epoch 11/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 1.3540 - accuracy: 0.3278 - val_loss: 1.7730 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.40269\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009980000474024565.\n",
      "Epoch 12/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 1.3532 - accuracy: 0.3444 - val_loss: 1.8015 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.40269\n",
      "Epoch 13/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 1.3520 - accuracy: 0.3389 - val_loss: 1.8118 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.40269\n",
      "Epoch 14/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 1.3432 - accuracy: 0.3611 - val_loss: 1.8064 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.40269\n",
      "Epoch 15/500\n",
      "360/360 [==============================] - 0s 259us/step - loss: 1.3260 - accuracy: 0.3917 - val_loss: 1.7934 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.40269\n",
      "Epoch 16/500\n",
      "360/360 [==============================] - 0s 236us/step - loss: 1.3239 - accuracy: 0.3833 - val_loss: 1.7733 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.40269\n",
      "Epoch 17/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 1.3084 - accuracy: 0.4583 - val_loss: 1.7579 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.40269\n",
      "Epoch 18/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 1.2889 - accuracy: 0.4861 - val_loss: 1.7493 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.40269\n",
      "Epoch 19/500\n",
      "360/360 [==============================] - 0s 243us/step - loss: 1.2860 - accuracy: 0.4444 - val_loss: 1.7443 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.40269\n",
      "Epoch 20/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 1.2674 - accuracy: 0.4917 - val_loss: 1.7406 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.40269\n",
      "Epoch 21/500\n",
      "360/360 [==============================] - 0s 217us/step - loss: 1.2414 - accuracy: 0.5111 - val_loss: 1.7416 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.40269\n",
      "Epoch 22/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 1.2209 - accuracy: 0.5333 - val_loss: 1.7554 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.40269\n",
      "Epoch 23/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 1.2031 - accuracy: 0.5472 - val_loss: 1.7816 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.40269\n",
      "Epoch 24/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 1.1724 - accuracy: 0.5694 - val_loss: 1.7872 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.40269\n",
      "Epoch 25/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 1.1525 - accuracy: 0.5861 - val_loss: 1.8092 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.40269\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009960040322039277.\n",
      "Epoch 26/500\n",
      "360/360 [==============================] - 0s 236us/step - loss: 1.1251 - accuracy: 0.5750 - val_loss: 1.8431 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.40269\n",
      "Epoch 27/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 1.1092 - accuracy: 0.5972 - val_loss: 1.8462 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.40269\n",
      "Epoch 28/500\n",
      "360/360 [==============================] - 0s 239us/step - loss: 1.0734 - accuracy: 0.5889 - val_loss: 1.8697 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.40269\n",
      "Epoch 29/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 1.0702 - accuracy: 0.6028 - val_loss: 1.8860 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.40269\n",
      "Epoch 30/500\n",
      "360/360 [==============================] - 0s 210us/step - loss: 1.0454 - accuracy: 0.5833 - val_loss: 1.8678 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.40269\n",
      "Epoch 31/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 1.0156 - accuracy: 0.5917 - val_loss: 1.8675 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.40269\n",
      "Epoch 32/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 1.0179 - accuracy: 0.5861 - val_loss: 1.8973 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.40269\n",
      "Epoch 33/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 1.0115 - accuracy: 0.5889 - val_loss: 1.8158 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.40269\n",
      "Epoch 34/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.9890 - accuracy: 0.5750 - val_loss: 1.7827 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.40269\n",
      "Epoch 35/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.9755 - accuracy: 0.6000 - val_loss: 1.7821 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.40269\n",
      "Epoch 36/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.9447 - accuracy: 0.6194 - val_loss: 1.7353 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.40269\n",
      "Epoch 37/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.9403 - accuracy: 0.5944 - val_loss: 1.6740 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.40269\n",
      "Epoch 38/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.9492 - accuracy: 0.5917 - val_loss: 1.6562 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.40269\n",
      "Epoch 39/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.9559 - accuracy: 0.6111 - val_loss: 1.6856 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.40269\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.000994011967210099.\n",
      "Epoch 40/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.9380 - accuracy: 0.6056 - val_loss: 1.5860 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.40269\n",
      "Epoch 41/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.9638 - accuracy: 0.5944 - val_loss: 1.5695 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.40269\n",
      "Epoch 42/500\n",
      "360/360 [==============================] - 0s 265us/step - loss: 0.8915 - accuracy: 0.5889 - val_loss: 1.6232 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.40269\n",
      "Epoch 43/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.9590 - accuracy: 0.5889 - val_loss: 1.5628 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.40269\n",
      "Epoch 44/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.9247 - accuracy: 0.5944 - val_loss: 1.4975 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.40269\n",
      "Epoch 45/500\n",
      "360/360 [==============================] - 0s 243us/step - loss: 0.9168 - accuracy: 0.6028 - val_loss: 1.4878 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.40269\n",
      "Epoch 46/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.8938 - accuracy: 0.6111 - val_loss: 1.6115 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.40269\n",
      "Epoch 47/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.8820 - accuracy: 0.6194 - val_loss: 1.5460 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.40269\n",
      "Epoch 48/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.8485 - accuracy: 0.6222 - val_loss: 1.4851 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.40269\n",
      "Epoch 49/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.8766 - accuracy: 0.6250 - val_loss: 1.5049 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.40269\n",
      "Epoch 50/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.8767 - accuracy: 0.6083 - val_loss: 1.5944 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.40269\n",
      "Epoch 51/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.8632 - accuracy: 0.6111 - val_loss: 1.6491 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.40269\n",
      "Epoch 52/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.8900 - accuracy: 0.6083 - val_loss: 1.5643 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.40269\n",
      "Epoch 53/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.8490 - accuracy: 0.6306 - val_loss: 1.5565 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.40269\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.000992023968603462.\n",
      "Epoch 54/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.8526 - accuracy: 0.6167 - val_loss: 1.5918 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.40269\n",
      "Epoch 55/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.8276 - accuracy: 0.6417 - val_loss: 1.6728 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.40269\n",
      "Epoch 56/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.8633 - accuracy: 0.6167 - val_loss: 1.6472 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.40269\n",
      "Epoch 57/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.8587 - accuracy: 0.6250 - val_loss: 1.5847 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.40269\n",
      "Epoch 58/500\n",
      "360/360 [==============================] - 0s 210us/step - loss: 0.8615 - accuracy: 0.6306 - val_loss: 1.5929 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.40269\n",
      "Epoch 59/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.8346 - accuracy: 0.6694 - val_loss: 1.6649 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.40269\n",
      "Epoch 60/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.8513 - accuracy: 0.6500 - val_loss: 1.6211 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.40269\n",
      "Epoch 61/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.8285 - accuracy: 0.6333 - val_loss: 1.5683 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.40269\n",
      "Epoch 62/500\n",
      "360/360 [==============================] - 0s 264us/step - loss: 0.8641 - accuracy: 0.6500 - val_loss: 1.5760 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.40269\n",
      "Epoch 63/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.8180 - accuracy: 0.6472 - val_loss: 1.5861 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.40269\n",
      "Epoch 64/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.8084 - accuracy: 0.6472 - val_loss: 1.5605 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.40269\n",
      "Epoch 65/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.8176 - accuracy: 0.6500 - val_loss: 1.5176 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.40269\n",
      "Epoch 66/500\n",
      "360/360 [==============================] - 0s 273us/step - loss: 0.7838 - accuracy: 0.6667 - val_loss: 1.4905 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.40269\n",
      "Epoch 67/500\n",
      "360/360 [==============================] - 0s 262us/step - loss: 0.8041 - accuracy: 0.6500 - val_loss: 1.5091 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.40269\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.000990039920201525.\n",
      "Epoch 68/500\n",
      "360/360 [==============================] - 0s 264us/step - loss: 0.8113 - accuracy: 0.6444 - val_loss: 1.4586 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.40269\n",
      "Epoch 69/500\n",
      "360/360 [==============================] - 0s 254us/step - loss: 0.7779 - accuracy: 0.6417 - val_loss: 1.4227 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.40269\n",
      "Epoch 70/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.8037 - accuracy: 0.6611 - val_loss: 1.4101 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.40269\n",
      "Epoch 71/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.7932 - accuracy: 0.6528 - val_loss: 1.4366 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.40269\n",
      "Epoch 72/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.7906 - accuracy: 0.6389 - val_loss: 1.3631 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.40269 to 1.36314, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 73/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.7629 - accuracy: 0.6583 - val_loss: 1.3495 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.36314 to 1.34950, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 74/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.7621 - accuracy: 0.6583 - val_loss: 1.3727 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.34950\n",
      "Epoch 75/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.7541 - accuracy: 0.6611 - val_loss: 1.3566 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.34950\n",
      "Epoch 76/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.7558 - accuracy: 0.6833 - val_loss: 1.3296 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.34950 to 1.32955, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 77/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.7797 - accuracy: 0.6556 - val_loss: 1.3294 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.32955 to 1.32945, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 78/500\n",
      "360/360 [==============================] - 0s 197us/step - loss: 0.7653 - accuracy: 0.6583 - val_loss: 1.3773 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.32945\n",
      "Epoch 79/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.7683 - accuracy: 0.6417 - val_loss: 1.3197 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.32945 to 1.31972, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 80/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.7514 - accuracy: 0.6806 - val_loss: 1.3236 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.31972\n",
      "Epoch 81/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.7653 - accuracy: 0.6722 - val_loss: 1.3499 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.31972\n",
      "Epoch 82/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.7513 - accuracy: 0.6417 - val_loss: 1.3707 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.31972\n",
      "Epoch 83/500\n",
      "360/360 [==============================] - 0s 209us/step - loss: 0.7753 - accuracy: 0.6556 - val_loss: 1.3266 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.31972\n",
      "Epoch 84/500\n",
      "360/360 [==============================] - 0s 207us/step - loss: 0.7440 - accuracy: 0.6667 - val_loss: 1.3331 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.31972\n",
      "Epoch 85/500\n",
      "360/360 [==============================] - 0s 244us/step - loss: 0.7153 - accuracy: 0.7083 - val_loss: 1.3334 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.31972\n",
      "Epoch 86/500\n",
      "360/360 [==============================] - 0s 202us/step - loss: 0.7031 - accuracy: 0.6833 - val_loss: 1.3823 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.31972\n",
      "Epoch 87/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.7619 - accuracy: 0.6472 - val_loss: 1.3208 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.31972\n",
      "Epoch 88/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.7011 - accuracy: 0.6944 - val_loss: 1.3385 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.31972\n",
      "Epoch 89/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.7231 - accuracy: 0.7139 - val_loss: 1.3172 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.31972 to 1.31717, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 90/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.7056 - accuracy: 0.6944 - val_loss: 1.3683 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.31717\n",
      "Epoch 91/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.7037 - accuracy: 0.6806 - val_loss: 1.3292 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.31717\n",
      "Epoch 92/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.6987 - accuracy: 0.6833 - val_loss: 1.3239 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.31717\n",
      "Epoch 93/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.6775 - accuracy: 0.7167 - val_loss: 1.3144 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.31717 to 1.31440, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 94/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.6942 - accuracy: 0.6944 - val_loss: 1.2958 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss improved from 1.31440 to 1.29582, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 95/500\n",
      "360/360 [==============================] - 0s 201us/step - loss: 0.7059 - accuracy: 0.7000 - val_loss: 1.3296 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.29582\n",
      "Epoch 96/500\n",
      "360/360 [==============================] - 0s 202us/step - loss: 0.7060 - accuracy: 0.6694 - val_loss: 1.2675 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.29582 to 1.26748, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 97/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.6545 - accuracy: 0.7083 - val_loss: 1.2851 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.26748\n",
      "Epoch 98/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.7375 - accuracy: 0.6639 - val_loss: 1.2574 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.26748 to 1.25738, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 99/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.6951 - accuracy: 0.6833 - val_loss: 1.2629 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.25738\n",
      "Epoch 100/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.6985 - accuracy: 0.6944 - val_loss: 1.2672 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.25738\n",
      "Epoch 101/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.7027 - accuracy: 0.6750 - val_loss: 1.2238 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.25738 to 1.22382, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 102/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.6646 - accuracy: 0.7111 - val_loss: 1.2174 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss improved from 1.22382 to 1.21744, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 103/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.7140 - accuracy: 0.7028 - val_loss: 1.1980 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss improved from 1.21744 to 1.19795, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 104/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.6773 - accuracy: 0.7000 - val_loss: 1.2154 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.19795\n",
      "Epoch 105/500\n",
      "360/360 [==============================] - 0s 200us/step - loss: 0.7016 - accuracy: 0.7056 - val_loss: 1.1832 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss improved from 1.19795 to 1.18325, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 106/500\n",
      "360/360 [==============================] - 0s 210us/step - loss: 0.6528 - accuracy: 0.7167 - val_loss: 1.1721 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.18325 to 1.17208, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 107/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.6562 - accuracy: 0.6944 - val_loss: 1.1805 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.17208\n",
      "Epoch 108/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.6375 - accuracy: 0.6917 - val_loss: 1.1849 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.17208\n",
      "Epoch 109/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.6445 - accuracy: 0.6917 - val_loss: 1.1984 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.17208\n",
      "Epoch 110/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.6559 - accuracy: 0.7278 - val_loss: 1.2031 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.17208\n",
      "Epoch 111/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.6044 - accuracy: 0.7222 - val_loss: 1.1968 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.17208\n",
      "Epoch 112/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.6264 - accuracy: 0.7167 - val_loss: 1.2106 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.17208\n",
      "Epoch 113/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.6330 - accuracy: 0.7139 - val_loss: 1.2030 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.17208\n",
      "Epoch 114/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.6260 - accuracy: 0.7139 - val_loss: 1.2030 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.17208\n",
      "Epoch 115/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.6420 - accuracy: 0.6944 - val_loss: 1.2060 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.17208\n",
      "Epoch 116/500\n",
      "360/360 [==============================] - 0s 239us/step - loss: 0.6373 - accuracy: 0.6806 - val_loss: 1.1693 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss improved from 1.17208 to 1.16935, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 117/500\n",
      "360/360 [==============================] - 0s 210us/step - loss: 0.5973 - accuracy: 0.7361 - val_loss: 1.1621 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss improved from 1.16935 to 1.16206, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 118/500\n",
      "360/360 [==============================] - 0s 202us/step - loss: 0.5942 - accuracy: 0.7139 - val_loss: 1.1567 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss improved from 1.16206 to 1.15667, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 119/500\n",
      "360/360 [==============================] - 0s 207us/step - loss: 0.6086 - accuracy: 0.7306 - val_loss: 1.1680 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.15667\n",
      "Epoch 120/500\n",
      "360/360 [==============================] - 0s 239us/step - loss: 0.5873 - accuracy: 0.7444 - val_loss: 1.1716 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.15667\n",
      "Epoch 121/500\n",
      "360/360 [==============================] - 0s 209us/step - loss: 0.6114 - accuracy: 0.7167 - val_loss: 1.1348 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss improved from 1.15667 to 1.13485, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 122/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.5638 - accuracy: 0.7583 - val_loss: 1.1133 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.13485 to 1.11331, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 123/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.6033 - accuracy: 0.7333 - val_loss: 1.1101 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.11331 to 1.11010, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 124/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.5751 - accuracy: 0.7472 - val_loss: 1.1394 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.11010\n",
      "Epoch 125/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.5893 - accuracy: 0.7278 - val_loss: 1.1417 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.11010\n",
      "Epoch 126/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.5500 - accuracy: 0.7444 - val_loss: 1.1364 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.11010\n",
      "Epoch 127/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.5453 - accuracy: 0.7500 - val_loss: 1.1429 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.11010\n",
      "Epoch 128/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.5519 - accuracy: 0.7472 - val_loss: 1.1449 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.11010\n",
      "Epoch 129/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.5584 - accuracy: 0.7333 - val_loss: 1.1358 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.11010\n",
      "Epoch 130/500\n",
      "360/360 [==============================] - 0s 224us/step - loss: 0.5547 - accuracy: 0.7417 - val_loss: 1.1318 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.11010\n",
      "Epoch 131/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.5649 - accuracy: 0.7472 - val_loss: 1.1236 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.11010\n",
      "Epoch 132/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.5218 - accuracy: 0.7722 - val_loss: 1.1154 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.11010\n",
      "Epoch 133/500\n",
      "360/360 [==============================] - 0s 271us/step - loss: 0.5369 - accuracy: 0.7444 - val_loss: 1.1113 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.11010\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.0009880598220042885.\n",
      "Epoch 134/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.5410 - accuracy: 0.7472 - val_loss: 1.1058 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00134: val_loss improved from 1.11010 to 1.10585, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 135/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.5244 - accuracy: 0.7500 - val_loss: 1.0615 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00135: val_loss improved from 1.10585 to 1.06148, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 136/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.5308 - accuracy: 0.7639 - val_loss: 1.0591 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00136: val_loss improved from 1.06148 to 1.05911, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 137/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.5104 - accuracy: 0.7750 - val_loss: 1.0984 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.05911\n",
      "Epoch 138/500\n",
      "360/360 [==============================] - 0s 204us/step - loss: 0.4917 - accuracy: 0.7750 - val_loss: 1.0966 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.05911\n",
      "Epoch 139/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.5332 - accuracy: 0.7611 - val_loss: 1.0624 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.05911\n",
      "Epoch 140/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.4797 - accuracy: 0.7750 - val_loss: 1.0121 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00140: val_loss improved from 1.05911 to 1.01211, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 141/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.5325 - accuracy: 0.7417 - val_loss: 0.9878 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00141: val_loss improved from 1.01211 to 0.98777, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 142/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.4954 - accuracy: 0.7694 - val_loss: 1.0104 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.98777\n",
      "Epoch 143/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.4933 - accuracy: 0.7750 - val_loss: 1.0337 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.98777\n",
      "Epoch 144/500\n",
      "360/360 [==============================] - 0s 269us/step - loss: 0.5217 - accuracy: 0.7389 - val_loss: 1.0545 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.98777\n",
      "Epoch 145/500\n",
      "360/360 [==============================] - 0s 255us/step - loss: 0.4726 - accuracy: 0.7667 - val_loss: 1.0221 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.98777\n",
      "Epoch 146/500\n",
      "360/360 [==============================] - 0s 256us/step - loss: 0.4874 - accuracy: 0.7667 - val_loss: 0.9756 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.98777 to 0.97558, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 147/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.4837 - accuracy: 0.7889 - val_loss: 0.9993 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.97558\n",
      "Epoch 148/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.4735 - accuracy: 0.7833 - val_loss: 1.0695 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.97558\n",
      "Epoch 149/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.4802 - accuracy: 0.7528 - val_loss: 1.0967 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.97558\n",
      "Epoch 150/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.4709 - accuracy: 0.7722 - val_loss: 1.0584 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.97558\n",
      "Epoch 151/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.4502 - accuracy: 0.8083 - val_loss: 0.9949 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.97558\n",
      "Epoch 152/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.4630 - accuracy: 0.7972 - val_loss: 1.0035 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.97558\n",
      "Epoch 153/500\n",
      "360/360 [==============================] - 0s 236us/step - loss: 0.4647 - accuracy: 0.8028 - val_loss: 1.0533 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.97558\n",
      "Epoch 154/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.4834 - accuracy: 0.7667 - val_loss: 1.1194 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.97558\n",
      "Epoch 155/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.4826 - accuracy: 0.7778 - val_loss: 1.1124 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.97558\n",
      "Epoch 156/500\n",
      "360/360 [==============================] - 0s 254us/step - loss: 0.4633 - accuracy: 0.7750 - val_loss: 1.0609 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.97558\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.000986083674011752.\n",
      "Epoch 157/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.4780 - accuracy: 0.7639 - val_loss: 0.9811 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.97558\n",
      "Epoch 158/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.4470 - accuracy: 0.8028 - val_loss: 0.9685 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.97558 to 0.96854, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 159/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.4529 - accuracy: 0.8056 - val_loss: 0.9749 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.96854\n",
      "Epoch 160/500\n",
      "360/360 [==============================] - 0s 236us/step - loss: 0.4523 - accuracy: 0.7583 - val_loss: 1.0423 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.96854\n",
      "Epoch 161/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.4332 - accuracy: 0.7972 - val_loss: 1.0847 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.96854\n",
      "Epoch 162/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.4443 - accuracy: 0.8028 - val_loss: 1.0126 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.96854\n",
      "Epoch 163/500\n",
      "360/360 [==============================] - 0s 258us/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.9338 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.96854 to 0.93378, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 164/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.4666 - accuracy: 0.7500 - val_loss: 0.9187 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.93378 to 0.91874, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 165/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.4711 - accuracy: 0.7667 - val_loss: 0.9602 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.91874\n",
      "Epoch 166/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.4449 - accuracy: 0.7722 - val_loss: 1.0075 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.91874\n",
      "Epoch 167/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.4607 - accuracy: 0.7944 - val_loss: 0.9278 - val_accuracy: 0.0500\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.91874\n",
      "Epoch 168/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.4204 - accuracy: 0.8139 - val_loss: 0.8873 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.91874 to 0.88730, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 169/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.4285 - accuracy: 0.7861 - val_loss: 0.9261 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.88730\n",
      "Epoch 170/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.4326 - accuracy: 0.7889 - val_loss: 0.9988 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.88730\n",
      "Epoch 171/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.4384 - accuracy: 0.7833 - val_loss: 1.0367 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.88730\n",
      "Epoch 172/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.4222 - accuracy: 0.7944 - val_loss: 1.0035 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.88730\n",
      "Epoch 173/500\n",
      "360/360 [==============================] - 0s 239us/step - loss: 0.4008 - accuracy: 0.8139 - val_loss: 0.9652 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.88730\n",
      "Epoch 174/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.4562 - accuracy: 0.7750 - val_loss: 0.9778 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.88730\n",
      "Epoch 175/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.4326 - accuracy: 0.7917 - val_loss: 1.0450 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.88730\n",
      "Epoch 176/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.4309 - accuracy: 0.8167 - val_loss: 1.0755 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.88730\n",
      "Epoch 177/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.4163 - accuracy: 0.7778 - val_loss: 1.0525 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.88730\n",
      "Epoch 178/500\n",
      "360/360 [==============================] - 0s 236us/step - loss: 0.4497 - accuracy: 0.7667 - val_loss: 1.0484 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.88730\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 0.0009841114762239157.\n",
      "Epoch 179/500\n",
      "360/360 [==============================] - 0s 200us/step - loss: 0.4519 - accuracy: 0.7722 - val_loss: 1.0581 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.88730\n",
      "Epoch 180/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.4188 - accuracy: 0.7944 - val_loss: 1.0426 - val_accuracy: 0.0250\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.88730\n",
      "Epoch 181/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.4566 - accuracy: 0.7944 - val_loss: 0.9293 - val_accuracy: 0.1000\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.88730\n",
      "Epoch 182/500\n",
      "360/360 [==============================] - 0s 252us/step - loss: 0.4327 - accuracy: 0.7750 - val_loss: 0.8454 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.88730 to 0.84537, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 183/500\n",
      "360/360 [==============================] - 0s 204us/step - loss: 0.4116 - accuracy: 0.7917 - val_loss: 0.8387 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.84537 to 0.83872, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 184/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.4154 - accuracy: 0.7889 - val_loss: 0.9375 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.83872\n",
      "Epoch 185/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.4147 - accuracy: 0.8000 - val_loss: 1.0058 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.83872\n",
      "Epoch 186/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.4076 - accuracy: 0.8222 - val_loss: 0.9716 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.83872\n",
      "Epoch 187/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.4198 - accuracy: 0.8028 - val_loss: 0.9264 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.83872\n",
      "Epoch 188/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.4144 - accuracy: 0.8028 - val_loss: 0.9340 - val_accuracy: 0.1000\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.83872\n",
      "Epoch 189/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.3902 - accuracy: 0.8194 - val_loss: 0.9901 - val_accuracy: 0.1000\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.83872\n",
      "Epoch 190/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.4274 - accuracy: 0.8083 - val_loss: 1.0109 - val_accuracy: 0.1000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.83872\n",
      "Epoch 191/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.4302 - accuracy: 0.7833 - val_loss: 0.9865 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.83872\n",
      "Epoch 192/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.4145 - accuracy: 0.8250 - val_loss: 0.9547 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.83872\n",
      "Epoch 193/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.3897 - accuracy: 0.8222 - val_loss: 0.9832 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.83872\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.00098214322864078.\n",
      "Epoch 194/500\n",
      "360/360 [==============================] - 0s 196us/step - loss: 0.3719 - accuracy: 0.8278 - val_loss: 1.0471 - val_accuracy: 0.0750\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.83872\n",
      "Epoch 195/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.4026 - accuracy: 0.8028 - val_loss: 1.0219 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.83872\n",
      "Epoch 196/500\n",
      "360/360 [==============================] - 0s 255us/step - loss: 0.3810 - accuracy: 0.8194 - val_loss: 0.9141 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.83872\n",
      "Epoch 197/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.4122 - accuracy: 0.8083 - val_loss: 0.8775 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.83872\n",
      "Epoch 198/500\n",
      "360/360 [==============================] - 0s 243us/step - loss: 0.3600 - accuracy: 0.8194 - val_loss: 0.8813 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.83872\n",
      "Epoch 199/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.4072 - accuracy: 0.8056 - val_loss: 0.8885 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.83872\n",
      "Epoch 200/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.3543 - accuracy: 0.8194 - val_loss: 0.8862 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.83872\n",
      "Epoch 201/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3849 - accuracy: 0.8111 - val_loss: 0.9212 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.83872\n",
      "Epoch 202/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.3610 - accuracy: 0.8333 - val_loss: 0.9318 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.83872\n",
      "Epoch 203/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.3792 - accuracy: 0.8083 - val_loss: 0.9984 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.83872\n",
      "Epoch 204/500\n",
      "360/360 [==============================] - 0s 209us/step - loss: 0.3737 - accuracy: 0.8194 - val_loss: 1.0626 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.83872\n",
      "Epoch 205/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.3854 - accuracy: 0.8083 - val_loss: 0.9883 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.83872\n",
      "Epoch 206/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3344 - accuracy: 0.8389 - val_loss: 0.9651 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.83872\n",
      "Epoch 207/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.3756 - accuracy: 0.8417 - val_loss: 0.9693 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.83872\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 0.000980178931262344.\n",
      "Epoch 208/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.3875 - accuracy: 0.8167 - val_loss: 0.9701 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.83872\n",
      "Epoch 209/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.3831 - accuracy: 0.8417 - val_loss: 0.9184 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.83872\n",
      "Epoch 210/500\n",
      "360/360 [==============================] - 0s 220us/step - loss: 0.3501 - accuracy: 0.8472 - val_loss: 0.8391 - val_accuracy: 0.2250\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.83872\n",
      "Epoch 211/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.3361 - accuracy: 0.8500 - val_loss: 0.8661 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.83872\n",
      "Epoch 212/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.3578 - accuracy: 0.8472 - val_loss: 0.9233 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.83872\n",
      "Epoch 213/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.3583 - accuracy: 0.8333 - val_loss: 0.9172 - val_accuracy: 0.2250\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.83872\n",
      "Epoch 214/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.3688 - accuracy: 0.8139 - val_loss: 0.8828 - val_accuracy: 0.2250\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.83872\n",
      "Epoch 215/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.3382 - accuracy: 0.8417 - val_loss: 0.8171 - val_accuracy: 0.2250\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.83872 to 0.81712, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 216/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.3918 - accuracy: 0.8194 - val_loss: 0.9518 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.81712\n",
      "Epoch 217/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.3522 - accuracy: 0.8444 - val_loss: 1.0319 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.81712\n",
      "Epoch 218/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.3607 - accuracy: 0.8250 - val_loss: 0.9771 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.81712\n",
      "Epoch 219/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.3617 - accuracy: 0.8278 - val_loss: 0.9308 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.81712\n",
      "Epoch 220/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.4101 - accuracy: 0.8083 - val_loss: 1.0566 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.81712\n",
      "Epoch 221/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3773 - accuracy: 0.8361 - val_loss: 1.0754 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.81712\n",
      "Epoch 222/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.3605 - accuracy: 0.8361 - val_loss: 0.9169 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.81712\n",
      "Epoch 223/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3310 - accuracy: 0.8556 - val_loss: 0.8172 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.81712\n",
      "Epoch 224/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.3716 - accuracy: 0.8361 - val_loss: 0.8370 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.81712\n",
      "Epoch 225/500\n",
      "360/360 [==============================] - 0s 244us/step - loss: 0.3398 - accuracy: 0.8500 - val_loss: 0.8364 - val_accuracy: 0.4250\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.81712\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 0.0009782185840886085.\n",
      "Epoch 226/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.3290 - accuracy: 0.8694 - val_loss: 0.7692 - val_accuracy: 0.4750\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.81712 to 0.76921, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 227/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.3499 - accuracy: 0.8472 - val_loss: 0.7497 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.76921 to 0.74966, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 228/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.3329 - accuracy: 0.8389 - val_loss: 0.7989 - val_accuracy: 0.4250\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.74966\n",
      "Epoch 229/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.3584 - accuracy: 0.8333 - val_loss: 0.9386 - val_accuracy: 0.2250\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.74966\n",
      "Epoch 230/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.3394 - accuracy: 0.8333 - val_loss: 1.0097 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.74966\n",
      "Epoch 231/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.3289 - accuracy: 0.8583 - val_loss: 0.9790 - val_accuracy: 0.1500\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.74966\n",
      "Epoch 232/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3197 - accuracy: 0.8611 - val_loss: 0.9576 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.74966\n",
      "Epoch 233/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.3538 - accuracy: 0.8500 - val_loss: 0.9206 - val_accuracy: 0.3250\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.74966\n",
      "Epoch 234/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.3181 - accuracy: 0.8444 - val_loss: 0.8567 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.74966\n",
      "Epoch 235/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.3228 - accuracy: 0.8611 - val_loss: 0.7442 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.74966 to 0.74422, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 236/500\n",
      "360/360 [==============================] - 0s 263us/step - loss: 0.3096 - accuracy: 0.8583 - val_loss: 0.7300 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.74422 to 0.73003, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 237/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3145 - accuracy: 0.8611 - val_loss: 0.8365 - val_accuracy: 0.4750\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.73003\n",
      "Epoch 238/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.3060 - accuracy: 0.8694 - val_loss: 0.9218 - val_accuracy: 0.3500\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.73003\n",
      "Epoch 239/500\n",
      "360/360 [==============================] - 0s 207us/step - loss: 0.3128 - accuracy: 0.8806 - val_loss: 0.9409 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.73003\n",
      "Epoch 240/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.3653 - accuracy: 0.8444 - val_loss: 0.9248 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.73003\n",
      "Epoch 241/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.3328 - accuracy: 0.8583 - val_loss: 1.0267 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.73003\n",
      "Epoch 242/500\n",
      "360/360 [==============================] - 0s 255us/step - loss: 0.3089 - accuracy: 0.8556 - val_loss: 1.0152 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.73003\n",
      "Epoch 243/500\n",
      "360/360 [==============================] - 0s 248us/step - loss: 0.3222 - accuracy: 0.8611 - val_loss: 0.8652 - val_accuracy: 0.3250\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.73003\n",
      "Epoch 244/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.3104 - accuracy: 0.8472 - val_loss: 0.7402 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.73003\n",
      "Epoch 245/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.3341 - accuracy: 0.8611 - val_loss: 0.7216 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.73003 to 0.72158, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 246/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.3064 - accuracy: 0.8694 - val_loss: 0.8067 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.72158\n",
      "Epoch 247/500\n",
      "360/360 [==============================] - 0s 249us/step - loss: 0.3024 - accuracy: 0.8833 - val_loss: 0.8348 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.72158\n",
      "Epoch 248/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.3378 - accuracy: 0.8694 - val_loss: 0.7523 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.72158\n",
      "Epoch 249/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.2898 - accuracy: 0.8861 - val_loss: 0.7767 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.72158\n",
      "Epoch 250/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.3408 - accuracy: 0.8444 - val_loss: 0.9753 - val_accuracy: 0.3500\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.72158\n",
      "Epoch 251/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.3299 - accuracy: 0.8472 - val_loss: 1.0291 - val_accuracy: 0.3250\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.72158\n",
      "Epoch 252/500\n",
      "360/360 [==============================] - 0s 262us/step - loss: 0.3384 - accuracy: 0.8472 - val_loss: 0.9180 - val_accuracy: 0.3500\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.72158\n",
      "Epoch 253/500\n",
      "360/360 [==============================] - 0s 260us/step - loss: 0.2821 - accuracy: 0.8917 - val_loss: 0.7843 - val_accuracy: 0.4250\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.72158\n",
      "Epoch 254/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.3523 - accuracy: 0.8556 - val_loss: 0.7720 - val_accuracy: 0.4750\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.72158\n",
      "Epoch 255/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.2678 - accuracy: 0.8750 - val_loss: 0.7978 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.72158\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 0.0009762621871195734.\n",
      "Epoch 256/500\n",
      "360/360 [==============================] - 0s 207us/step - loss: 0.3144 - accuracy: 0.8861 - val_loss: 0.8124 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.72158\n",
      "Epoch 257/500\n",
      "360/360 [==============================] - 0s 257us/step - loss: 0.3300 - accuracy: 0.8667 - val_loss: 0.8105 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.72158\n",
      "Epoch 258/500\n",
      "360/360 [==============================] - 0s 255us/step - loss: 0.3091 - accuracy: 0.8667 - val_loss: 0.7972 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.72158\n",
      "Epoch 259/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.2902 - accuracy: 0.8750 - val_loss: 0.8384 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.72158\n",
      "Epoch 260/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.3055 - accuracy: 0.8667 - val_loss: 0.9292 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.72158\n",
      "Epoch 261/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.2922 - accuracy: 0.8806 - val_loss: 0.9871 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.72158\n",
      "Epoch 262/500\n",
      "360/360 [==============================] - 0s 251us/step - loss: 0.3043 - accuracy: 0.8750 - val_loss: 0.8796 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.72158\n",
      "Epoch 263/500\n",
      "360/360 [==============================] - 0s 243us/step - loss: 0.2858 - accuracy: 0.8722 - val_loss: 0.7629 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.72158\n",
      "Epoch 264/500\n",
      "360/360 [==============================] - 0s 207us/step - loss: 0.2745 - accuracy: 0.8917 - val_loss: 0.7193 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.72158 to 0.71931, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 265/500\n",
      "360/360 [==============================] - 0s 217us/step - loss: 0.2893 - accuracy: 0.8722 - val_loss: 0.7471 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.71931\n",
      "Epoch 266/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.2716 - accuracy: 0.8972 - val_loss: 0.7894 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.71931\n",
      "Epoch 267/500\n",
      "360/360 [==============================] - 0s 250us/step - loss: 0.2785 - accuracy: 0.8917 - val_loss: 0.8026 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.71931\n",
      "Epoch 268/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.2928 - accuracy: 0.8833 - val_loss: 0.8140 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.71931\n",
      "Epoch 269/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.2781 - accuracy: 0.8972 - val_loss: 0.8566 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.71931\n",
      "Epoch 270/500\n",
      "360/360 [==============================] - 0s 224us/step - loss: 0.2747 - accuracy: 0.8750 - val_loss: 0.8729 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.71931\n",
      "Epoch 271/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.2594 - accuracy: 0.9083 - val_loss: 0.8547 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.71931\n",
      "Epoch 272/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.2507 - accuracy: 0.9139 - val_loss: 0.8269 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.71931\n",
      "Epoch 273/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.2472 - accuracy: 0.9028 - val_loss: 0.8141 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.71931\n",
      "Epoch 274/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.2591 - accuracy: 0.8944 - val_loss: 0.7583 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.71931\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 0.0009743096822639927.\n",
      "Epoch 275/500\n",
      "360/360 [==============================] - 0s 201us/step - loss: 0.2479 - accuracy: 0.9139 - val_loss: 0.7424 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.71931\n",
      "Epoch 276/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.2893 - accuracy: 0.8861 - val_loss: 0.8177 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.71931\n",
      "Epoch 277/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.2597 - accuracy: 0.9000 - val_loss: 0.8457 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.71931\n",
      "Epoch 278/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.2695 - accuracy: 0.8972 - val_loss: 0.8038 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.71931\n",
      "Epoch 279/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.2537 - accuracy: 0.8972 - val_loss: 0.7552 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.71931\n",
      "Epoch 280/500\n",
      "360/360 [==============================] - 0s 253us/step - loss: 0.2480 - accuracy: 0.9000 - val_loss: 0.7099 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.71931 to 0.70989, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 281/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.2482 - accuracy: 0.8972 - val_loss: 0.7583 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.70989\n",
      "Epoch 282/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.2588 - accuracy: 0.9028 - val_loss: 0.7750 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.70989\n",
      "Epoch 283/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.2440 - accuracy: 0.9083 - val_loss: 0.7835 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.70989\n",
      "Epoch 284/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.2841 - accuracy: 0.8806 - val_loss: 0.8379 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.70989\n",
      "Epoch 285/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.2463 - accuracy: 0.9139 - val_loss: 0.9299 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.70989\n",
      "Epoch 286/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.2455 - accuracy: 0.9056 - val_loss: 0.8871 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.70989\n",
      "Epoch 287/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.2508 - accuracy: 0.9111 - val_loss: 0.7919 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.70989\n",
      "Epoch 288/500\n",
      "360/360 [==============================] - 0s 245us/step - loss: 0.2295 - accuracy: 0.9056 - val_loss: 0.7587 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.70989\n",
      "Epoch 289/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.2740 - accuracy: 0.9111 - val_loss: 0.7330 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.70989\n",
      "Epoch 290/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.2364 - accuracy: 0.9111 - val_loss: 0.7470 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.70989\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 0.0009723610695218667.\n",
      "Epoch 291/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.2447 - accuracy: 0.8889 - val_loss: 0.7108 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.70989\n",
      "Epoch 292/500\n",
      "360/360 [==============================] - 0s 220us/step - loss: 0.2163 - accuracy: 0.9250 - val_loss: 0.7428 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.70989\n",
      "Epoch 293/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.2430 - accuracy: 0.8972 - val_loss: 0.8059 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.70989\n",
      "Epoch 294/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.2270 - accuracy: 0.9000 - val_loss: 0.8273 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.70989\n",
      "Epoch 295/500\n",
      "360/360 [==============================] - 0s 217us/step - loss: 0.2358 - accuracy: 0.9000 - val_loss: 0.8024 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.70989\n",
      "Epoch 296/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.2242 - accuracy: 0.9056 - val_loss: 0.7265 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.70989\n",
      "Epoch 297/500\n",
      "360/360 [==============================] - 0s 209us/step - loss: 0.2316 - accuracy: 0.8972 - val_loss: 0.6738 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.70989 to 0.67378, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 298/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.2266 - accuracy: 0.9167 - val_loss: 0.6630 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.67378 to 0.66301, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 299/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.2335 - accuracy: 0.9000 - val_loss: 0.6875 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.66301\n",
      "Epoch 300/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.2094 - accuracy: 0.9056 - val_loss: 0.7146 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.66301\n",
      "Epoch 301/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.2066 - accuracy: 0.9139 - val_loss: 0.7410 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.66301\n",
      "Epoch 302/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.2507 - accuracy: 0.9028 - val_loss: 0.7673 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.66301\n",
      "Epoch 303/500\n",
      "360/360 [==============================] - 0s 220us/step - loss: 0.2152 - accuracy: 0.9194 - val_loss: 0.8448 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.66301\n",
      "Epoch 304/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.1996 - accuracy: 0.9194 - val_loss: 0.8481 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.66301\n",
      "Epoch 305/500\n",
      "360/360 [==============================] - 0s 224us/step - loss: 0.2390 - accuracy: 0.9083 - val_loss: 0.8125 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.66301\n",
      "Epoch 306/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.2073 - accuracy: 0.9278 - val_loss: 0.7543 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.66301\n",
      "Epoch 307/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.2156 - accuracy: 0.9056 - val_loss: 0.6511 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.66301 to 0.65108, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 308/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.2130 - accuracy: 0.9167 - val_loss: 0.6016 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.65108 to 0.60158, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 309/500\n",
      "360/360 [==============================] - 0s 255us/step - loss: 0.2481 - accuracy: 0.9167 - val_loss: 0.6384 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.60158\n",
      "Epoch 310/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.2270 - accuracy: 0.9028 - val_loss: 0.7151 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.60158\n",
      "Epoch 311/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.1927 - accuracy: 0.9194 - val_loss: 0.8321 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.60158\n",
      "Epoch 312/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.1844 - accuracy: 0.9306 - val_loss: 0.9491 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.60158\n",
      "Epoch 313/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.1954 - accuracy: 0.9194 - val_loss: 0.9387 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.60158\n",
      "Epoch 314/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.2155 - accuracy: 0.9139 - val_loss: 0.8997 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.60158\n",
      "Epoch 315/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.2084 - accuracy: 0.9056 - val_loss: 0.7935 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.60158\n",
      "Epoch 316/500\n",
      "360/360 [==============================] - 0s 269us/step - loss: 0.2073 - accuracy: 0.9222 - val_loss: 0.7252 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.60158\n",
      "Epoch 317/500\n",
      "360/360 [==============================] - 0s 243us/step - loss: 0.2136 - accuracy: 0.9167 - val_loss: 0.6612 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.60158\n",
      "Epoch 318/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.2250 - accuracy: 0.9278 - val_loss: 0.6312 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.60158\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 0.0009704163488931954.\n",
      "Epoch 319/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.1854 - accuracy: 0.9250 - val_loss: 0.6621 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.60158\n",
      "Epoch 320/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.1875 - accuracy: 0.9194 - val_loss: 0.7031 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.60158\n",
      "Epoch 321/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.2043 - accuracy: 0.9222 - val_loss: 0.7733 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.60158\n",
      "Epoch 322/500\n",
      "360/360 [==============================] - 0s 259us/step - loss: 0.1958 - accuracy: 0.9194 - val_loss: 0.7877 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.60158\n",
      "Epoch 323/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.2108 - accuracy: 0.9111 - val_loss: 0.7752 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.60158\n",
      "Epoch 324/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.1763 - accuracy: 0.9389 - val_loss: 0.7239 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.60158\n",
      "Epoch 325/500\n",
      "360/360 [==============================] - 0s 265us/step - loss: 0.1773 - accuracy: 0.9417 - val_loss: 0.6893 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.60158\n",
      "Epoch 326/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.1990 - accuracy: 0.9250 - val_loss: 0.6268 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.60158\n",
      "Epoch 327/500\n",
      "360/360 [==============================] - 0s 210us/step - loss: 0.2156 - accuracy: 0.9194 - val_loss: 0.6347 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.60158\n",
      "Epoch 328/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.1804 - accuracy: 0.9139 - val_loss: 0.6588 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.60158\n",
      "Epoch 329/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.2043 - accuracy: 0.9250 - val_loss: 0.7380 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.60158\n",
      "Epoch 330/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.1760 - accuracy: 0.9333 - val_loss: 0.7976 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.60158\n",
      "Epoch 331/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1762 - accuracy: 0.9111 - val_loss: 0.7978 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.60158\n",
      "Epoch 332/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.2084 - accuracy: 0.9111 - val_loss: 0.7402 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.60158\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 0.0009684755203779787.\n",
      "Epoch 333/500\n",
      "360/360 [==============================] - 0s 220us/step - loss: 0.1983 - accuracy: 0.9222 - val_loss: 0.6692 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.60158\n",
      "Epoch 334/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.1619 - accuracy: 0.9472 - val_loss: 0.6051 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.60158\n",
      "Epoch 335/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.1741 - accuracy: 0.9306 - val_loss: 0.6158 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.60158\n",
      "Epoch 336/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.1746 - accuracy: 0.9250 - val_loss: 0.6654 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.60158\n",
      "Epoch 337/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.1704 - accuracy: 0.9444 - val_loss: 0.7500 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.60158\n",
      "Epoch 338/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.1911 - accuracy: 0.9222 - val_loss: 0.8308 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.60158\n",
      "Epoch 339/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.1902 - accuracy: 0.9278 - val_loss: 0.8820 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.60158\n",
      "Epoch 340/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.2005 - accuracy: 0.9167 - val_loss: 0.8815 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.60158\n",
      "Epoch 341/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.1465 - accuracy: 0.9417 - val_loss: 0.8565 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.60158\n",
      "Epoch 342/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1772 - accuracy: 0.9361 - val_loss: 0.7184 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.60158\n",
      "Epoch 343/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.2040 - accuracy: 0.9111 - val_loss: 0.6738 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.60158\n",
      "Epoch 344/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.2084 - accuracy: 0.9083 - val_loss: 0.5417 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.60158 to 0.54167, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 345/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.1868 - accuracy: 0.9472 - val_loss: 0.5423 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.54167\n",
      "Epoch 346/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.2374 - accuracy: 0.9111 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.54167\n",
      "Epoch 347/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.2113 - accuracy: 0.9194 - val_loss: 0.7524 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.54167\n",
      "Epoch 348/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.2626 - accuracy: 0.9000 - val_loss: 0.7212 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.54167\n",
      "Epoch 349/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.1590 - accuracy: 0.9528 - val_loss: 0.7969 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.54167\n",
      "Epoch 350/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.2553 - accuracy: 0.8972 - val_loss: 0.7935 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.54167\n",
      "Epoch 351/500\n",
      "360/360 [==============================] - 0s 247us/step - loss: 0.1682 - accuracy: 0.9389 - val_loss: 0.8655 - val_accuracy: 0.4750\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.54167\n",
      "Epoch 352/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.3158 - accuracy: 0.8806 - val_loss: 0.7737 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.54167\n",
      "Epoch 353/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.1658 - accuracy: 0.9417 - val_loss: 0.8455 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.54167\n",
      "Epoch 354/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.3489 - accuracy: 0.8694 - val_loss: 0.7018 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.54167\n",
      "\n",
      "Epoch 00354: ReduceLROnPlateau reducing learning rate to 0.0009665385839762166.\n",
      "Epoch 355/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.2349 - accuracy: 0.9194 - val_loss: 0.7127 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.54167\n",
      "Epoch 356/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.2169 - accuracy: 0.9028 - val_loss: 0.6979 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.54167\n",
      "Epoch 357/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.2777 - accuracy: 0.8889 - val_loss: 0.5425 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.54167\n",
      "Epoch 358/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.1894 - accuracy: 0.9139 - val_loss: 0.5906 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.54167\n",
      "Epoch 359/500\n",
      "360/360 [==============================] - 0s 256us/step - loss: 0.1685 - accuracy: 0.9333 - val_loss: 0.6374 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.54167\n",
      "Epoch 360/500\n",
      "360/360 [==============================] - 0s 249us/step - loss: 0.2407 - accuracy: 0.9250 - val_loss: 0.6174 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.54167\n",
      "Epoch 361/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.2206 - accuracy: 0.9194 - val_loss: 0.6658 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.54167\n",
      "Epoch 362/500\n",
      "360/360 [==============================] - 0s 235us/step - loss: 0.1849 - accuracy: 0.9361 - val_loss: 0.7789 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.54167\n",
      "Epoch 363/500\n",
      "360/360 [==============================] - 0s 236us/step - loss: 0.1931 - accuracy: 0.9444 - val_loss: 0.8816 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.54167\n",
      "Epoch 364/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.2103 - accuracy: 0.9139 - val_loss: 0.8912 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.54167\n",
      "Epoch 365/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.1774 - accuracy: 0.9444 - val_loss: 0.8563 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.54167\n",
      "Epoch 366/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.1843 - accuracy: 0.9222 - val_loss: 0.8013 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.54167\n",
      "Epoch 367/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.1872 - accuracy: 0.9278 - val_loss: 0.7249 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.54167\n",
      "Epoch 368/500\n",
      "360/360 [==============================] - 0s 204us/step - loss: 0.1902 - accuracy: 0.9333 - val_loss: 0.6479 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.54167\n",
      "\n",
      "Epoch 00368: ReduceLROnPlateau reducing learning rate to 0.0009646054815966636.\n",
      "Epoch 369/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.6017 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.54167\n",
      "Epoch 370/500\n",
      "360/360 [==============================] - 0s 250us/step - loss: 0.1698 - accuracy: 0.9306 - val_loss: 0.5474 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.54167\n",
      "Epoch 371/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1875 - accuracy: 0.9278 - val_loss: 0.5576 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.54167\n",
      "Epoch 372/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.1642 - accuracy: 0.9444 - val_loss: 0.6203 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.54167\n",
      "Epoch 373/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1484 - accuracy: 0.9500 - val_loss: 0.7069 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.54167\n",
      "Epoch 374/500\n",
      "360/360 [==============================] - 0s 246us/step - loss: 0.1574 - accuracy: 0.9528 - val_loss: 0.7901 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.54167\n",
      "Epoch 375/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.1715 - accuracy: 0.9444 - val_loss: 0.8911 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.54167\n",
      "Epoch 376/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.1479 - accuracy: 0.9528 - val_loss: 0.9564 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.54167\n",
      "Epoch 377/500\n",
      "360/360 [==============================] - 0s 253us/step - loss: 0.1550 - accuracy: 0.9528 - val_loss: 0.9267 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.54167\n",
      "Epoch 378/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.1644 - accuracy: 0.9417 - val_loss: 0.7646 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.54167\n",
      "Epoch 379/500\n",
      "360/360 [==============================] - 0s 243us/step - loss: 0.1497 - accuracy: 0.9611 - val_loss: 0.6076 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.54167\n",
      "Epoch 380/500\n",
      "360/360 [==============================] - 0s 242us/step - loss: 0.1666 - accuracy: 0.9389 - val_loss: 0.5103 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.54167 to 0.51025, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 381/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.1537 - accuracy: 0.9361 - val_loss: 0.4946 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.51025 to 0.49463, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 382/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.1704 - accuracy: 0.9444 - val_loss: 0.5470 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.49463\n",
      "Epoch 383/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.1313 - accuracy: 0.9611 - val_loss: 0.6400 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.49463\n",
      "Epoch 384/500\n",
      "360/360 [==============================] - 0s 249us/step - loss: 0.1179 - accuracy: 0.9639 - val_loss: 0.7452 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.49463\n",
      "Epoch 385/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.1460 - accuracy: 0.9583 - val_loss: 0.8112 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.49463\n",
      "Epoch 386/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1632 - accuracy: 0.9444 - val_loss: 0.7808 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.49463\n",
      "Epoch 387/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.1355 - accuracy: 0.9500 - val_loss: 0.7336 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.49463\n",
      "Epoch 388/500\n",
      "360/360 [==============================] - 0s 232us/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.6941 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.49463\n",
      "Epoch 389/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.1208 - accuracy: 0.9583 - val_loss: 0.6335 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.49463\n",
      "Epoch 390/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.1497 - accuracy: 0.9611 - val_loss: 0.6304 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.49463\n",
      "Epoch 391/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1319 - accuracy: 0.9444 - val_loss: 0.6445 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.49463\n",
      "\n",
      "Epoch 00391: ReduceLROnPlateau reducing learning rate to 0.0009626762713305652.\n",
      "Epoch 392/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.1196 - accuracy: 0.9639 - val_loss: 0.6687 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.49463\n",
      "Epoch 393/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.1374 - accuracy: 0.9556 - val_loss: 0.6969 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.49463\n",
      "Epoch 394/500\n",
      "360/360 [==============================] - 0s 220us/step - loss: 0.1204 - accuracy: 0.9611 - val_loss: 0.7058 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.49463\n",
      "Epoch 395/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.1351 - accuracy: 0.9528 - val_loss: 0.7300 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.49463\n",
      "Epoch 396/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.7619 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.49463\n",
      "Epoch 397/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.1333 - accuracy: 0.9528 - val_loss: 0.7879 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.49463\n",
      "Epoch 398/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.1472 - accuracy: 0.9417 - val_loss: 0.8291 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.49463\n",
      "Epoch 399/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.1256 - accuracy: 0.9444 - val_loss: 0.8154 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.49463\n",
      "Epoch 400/500\n",
      "360/360 [==============================] - 0s 220us/step - loss: 0.1022 - accuracy: 0.9639 - val_loss: 0.7685 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.49463\n",
      "Epoch 401/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.1285 - accuracy: 0.9556 - val_loss: 0.7201 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.49463\n",
      "Epoch 402/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.1204 - accuracy: 0.9556 - val_loss: 0.6404 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.49463\n",
      "Epoch 403/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.5939 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.49463\n",
      "Epoch 404/500\n",
      "360/360 [==============================] - 0s 224us/step - loss: 0.1038 - accuracy: 0.9667 - val_loss: 0.5767 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.49463\n",
      "Epoch 405/500\n",
      "360/360 [==============================] - 0s 224us/step - loss: 0.1186 - accuracy: 0.9528 - val_loss: 0.5861 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.49463\n",
      "\n",
      "Epoch 00405: ReduceLROnPlateau reducing learning rate to 0.0009607508950866759.\n",
      "Epoch 406/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.1349 - accuracy: 0.9361 - val_loss: 0.6245 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.49463\n",
      "Epoch 407/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.1207 - accuracy: 0.9528 - val_loss: 0.7564 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.49463\n",
      "Epoch 408/500\n",
      "360/360 [==============================] - 0s 217us/step - loss: 0.1276 - accuracy: 0.9556 - val_loss: 0.8704 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.49463\n",
      "Epoch 409/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.9634 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.49463\n",
      "Epoch 410/500\n",
      "360/360 [==============================] - 0s 204us/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.9439 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.49463\n",
      "Epoch 411/500\n",
      "360/360 [==============================] - 0s 255us/step - loss: 0.1273 - accuracy: 0.9500 - val_loss: 0.8843 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.49463\n",
      "Epoch 412/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.1125 - accuracy: 0.9639 - val_loss: 0.7811 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.49463\n",
      "Epoch 413/500\n",
      "360/360 [==============================] - 0s 226us/step - loss: 0.1346 - accuracy: 0.9528 - val_loss: 0.6068 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.49463\n",
      "Epoch 414/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.1019 - accuracy: 0.9667 - val_loss: 0.4918 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00414: val_loss improved from 0.49463 to 0.49184, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 415/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.1179 - accuracy: 0.9556 - val_loss: 0.4527 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00415: val_loss improved from 0.49184 to 0.45271, saving model to retina_result_weights.best.hdf5\n",
      "Epoch 416/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.1232 - accuracy: 0.9583 - val_loss: 0.5038 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.45271\n",
      "Epoch 417/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.1260 - accuracy: 0.9667 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.45271\n",
      "Epoch 418/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.1094 - accuracy: 0.9528 - val_loss: 0.7672 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.45271\n",
      "Epoch 419/500\n",
      "360/360 [==============================] - 0s 231us/step - loss: 0.1238 - accuracy: 0.9556 - val_loss: 0.9058 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.45271\n",
      "Epoch 420/500\n",
      "360/360 [==============================] - 0s 212us/step - loss: 0.1312 - accuracy: 0.9389 - val_loss: 0.9212 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.45271\n",
      "Epoch 421/500\n",
      "360/360 [==============================] - 0s 239us/step - loss: 0.1333 - accuracy: 0.9583 - val_loss: 0.8634 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.45271\n",
      "Epoch 422/500\n",
      "360/360 [==============================] - 0s 209us/step - loss: 0.0971 - accuracy: 0.9667 - val_loss: 0.7778 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.45271\n",
      "Epoch 423/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.1052 - accuracy: 0.9667 - val_loss: 0.7211 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.45271\n",
      "Epoch 424/500\n",
      "360/360 [==============================] - 0s 217us/step - loss: 0.1425 - accuracy: 0.9472 - val_loss: 0.6892 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.45271\n",
      "Epoch 425/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.0900 - accuracy: 0.9778 - val_loss: 0.6850 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00425: ReduceLROnPlateau reducing learning rate to 0.0009588294109562412.\n",
      "Epoch 426/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.0972 - accuracy: 0.9806 - val_loss: 0.6779 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.45271\n",
      "Epoch 427/500\n",
      "360/360 [==============================] - 0s 217us/step - loss: 0.1291 - accuracy: 0.9611 - val_loss: 0.6687 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.45271\n",
      "Epoch 428/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.1077 - accuracy: 0.9639 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.45271\n",
      "Epoch 429/500\n",
      "360/360 [==============================] - 0s 200us/step - loss: 0.0782 - accuracy: 0.9750 - val_loss: 0.7668 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.45271\n",
      "Epoch 430/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.1255 - accuracy: 0.9528 - val_loss: 0.7959 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.45271\n",
      "Epoch 431/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.1108 - accuracy: 0.9639 - val_loss: 0.7754 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.45271\n",
      "Epoch 432/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.0894 - accuracy: 0.9639 - val_loss: 0.7625 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.45271\n",
      "Epoch 433/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.0982 - accuracy: 0.9667 - val_loss: 0.7476 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.45271\n",
      "Epoch 434/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.0858 - accuracy: 0.9694 - val_loss: 0.7477 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.45271\n",
      "Epoch 435/500\n",
      "360/360 [==============================] - 0s 245us/step - loss: 0.0956 - accuracy: 0.9611 - val_loss: 0.7346 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.45271\n",
      "Epoch 436/500\n",
      "360/360 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.9694 - val_loss: 0.7112 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.45271\n",
      "Epoch 437/500\n",
      "360/360 [==============================] - 0s 224us/step - loss: 0.0848 - accuracy: 0.9722 - val_loss: 0.6667 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.45271\n",
      "Epoch 438/500\n",
      "360/360 [==============================] - 0s 202us/step - loss: 0.0940 - accuracy: 0.9694 - val_loss: 0.6153 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.45271\n",
      "Epoch 439/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.0981 - accuracy: 0.9667 - val_loss: 0.6332 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00439: ReduceLROnPlateau reducing learning rate to 0.0009569117608480155.\n",
      "Epoch 440/500\n",
      "360/360 [==============================] - 0s 201us/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.7004 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.45271\n",
      "Epoch 441/500\n",
      "360/360 [==============================] - 0s 225us/step - loss: 0.0819 - accuracy: 0.9667 - val_loss: 0.8086 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.45271\n",
      "Epoch 442/500\n",
      "360/360 [==============================] - 0s 210us/step - loss: 0.1055 - accuracy: 0.9667 - val_loss: 0.9065 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.45271\n",
      "Epoch 443/500\n",
      "360/360 [==============================] - 0s 238us/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.9266 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.45271\n",
      "Epoch 444/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.1230 - accuracy: 0.9639 - val_loss: 0.9010 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.45271\n",
      "Epoch 445/500\n",
      "360/360 [==============================] - 0s 239us/step - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.8288 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.45271\n",
      "Epoch 446/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.0840 - accuracy: 0.9694 - val_loss: 0.7576 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.45271\n",
      "Epoch 447/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.0962 - accuracy: 0.9639 - val_loss: 0.7028 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.45271\n",
      "Epoch 448/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.0996 - accuracy: 0.9694 - val_loss: 0.6960 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.45271\n",
      "Epoch 449/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.0872 - accuracy: 0.9750 - val_loss: 0.6433 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.45271\n",
      "Epoch 450/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.0963 - accuracy: 0.9667 - val_loss: 0.6024 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.45271\n",
      "Epoch 451/500\n",
      "360/360 [==============================] - 0s 268us/step - loss: 0.0826 - accuracy: 0.9694 - val_loss: 0.5993 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.45271\n",
      "Epoch 452/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.6499 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.45271\n",
      "Epoch 453/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.0944 - accuracy: 0.9667 - val_loss: 0.7201 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00453: ReduceLROnPlateau reducing learning rate to 0.000954997944761999.\n",
      "Epoch 454/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.0730 - accuracy: 0.9694 - val_loss: 0.7852 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.45271\n",
      "Epoch 455/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.1175 - accuracy: 0.9611 - val_loss: 0.8617 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.45271\n",
      "Epoch 456/500\n",
      "360/360 [==============================] - 0s 253us/step - loss: 0.0762 - accuracy: 0.9806 - val_loss: 0.8745 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.45271\n",
      "Epoch 457/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.0926 - accuracy: 0.9639 - val_loss: 0.8312 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.45271\n",
      "Epoch 458/500\n",
      "360/360 [==============================] - 0s 245us/step - loss: 0.0991 - accuracy: 0.9694 - val_loss: 0.7450 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.45271\n",
      "Epoch 459/500\n",
      "360/360 [==============================] - 0s 205us/step - loss: 0.0944 - accuracy: 0.9694 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.45271\n",
      "Epoch 460/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.0955 - accuracy: 0.9639 - val_loss: 0.5962 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.45271\n",
      "Epoch 461/500\n",
      "360/360 [==============================] - 0s 201us/step - loss: 0.0929 - accuracy: 0.9722 - val_loss: 0.5554 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.45271\n",
      "Epoch 462/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.0928 - accuracy: 0.9694 - val_loss: 0.5749 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.45271\n",
      "Epoch 463/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.0759 - accuracy: 0.9778 - val_loss: 0.5932 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.45271\n",
      "Epoch 464/500\n",
      "360/360 [==============================] - 0s 230us/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.6808 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.45271\n",
      "Epoch 465/500\n",
      "360/360 [==============================] - 0s 216us/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.8057 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.45271\n",
      "Epoch 466/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.1059 - accuracy: 0.9556 - val_loss: 0.8378 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.45271\n",
      "Epoch 467/500\n",
      "360/360 [==============================] - 0s 206us/step - loss: 0.0860 - accuracy: 0.9722 - val_loss: 0.7167 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00467: ReduceLROnPlateau reducing learning rate to 0.0009530879626981914.\n",
      "Epoch 468/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.1083 - accuracy: 0.9611 - val_loss: 0.6207 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.45271\n",
      "Epoch 469/500\n",
      "360/360 [==============================] - 0s 219us/step - loss: 0.0999 - accuracy: 0.9583 - val_loss: 0.5702 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.45271\n",
      "Epoch 470/500\n",
      "360/360 [==============================] - 0s 229us/step - loss: 0.0951 - accuracy: 0.9639 - val_loss: 0.5510 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.45271\n",
      "Epoch 471/500\n",
      "360/360 [==============================] - 0s 218us/step - loss: 0.0923 - accuracy: 0.9694 - val_loss: 0.5472 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.45271\n",
      "Epoch 472/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.5845 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.45271\n",
      "Epoch 473/500\n",
      "360/360 [==============================] - 0s 249us/step - loss: 0.0641 - accuracy: 0.9750 - val_loss: 0.6316 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.45271\n",
      "Epoch 474/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.1139 - accuracy: 0.9528 - val_loss: 0.7632 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.45271\n",
      "Epoch 475/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.0741 - accuracy: 0.9778 - val_loss: 0.8442 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.45271\n",
      "Epoch 476/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.0895 - accuracy: 0.9639 - val_loss: 0.8668 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.45271\n",
      "Epoch 477/500\n",
      "360/360 [==============================] - 0s 250us/step - loss: 0.0660 - accuracy: 0.9778 - val_loss: 0.8495 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.45271\n",
      "Epoch 478/500\n",
      "360/360 [==============================] - 0s 233us/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.8393 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.45271\n",
      "Epoch 479/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.0681 - accuracy: 0.9833 - val_loss: 0.7840 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.45271\n",
      "Epoch 480/500\n",
      "360/360 [==============================] - 0s 241us/step - loss: 0.0987 - accuracy: 0.9750 - val_loss: 0.7481 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.45271\n",
      "Epoch 481/500\n",
      "360/360 [==============================] - 0s 199us/step - loss: 0.0839 - accuracy: 0.9750 - val_loss: 0.6933 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00481: ReduceLROnPlateau reducing learning rate to 0.0009511818146565929.\n",
      "Epoch 482/500\n",
      "360/360 [==============================] - 0s 221us/step - loss: 0.0863 - accuracy: 0.9722 - val_loss: 0.6234 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.45271\n",
      "Epoch 483/500\n",
      "360/360 [==============================] - 0s 222us/step - loss: 0.1013 - accuracy: 0.9750 - val_loss: 0.5412 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.45271\n",
      "Epoch 484/500\n",
      "360/360 [==============================] - 0s 228us/step - loss: 0.0673 - accuracy: 0.9722 - val_loss: 0.5145 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.45271\n",
      "Epoch 485/500\n",
      "360/360 [==============================] - 0s 204us/step - loss: 0.0691 - accuracy: 0.9722 - val_loss: 0.5527 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.45271\n",
      "Epoch 486/500\n",
      "360/360 [==============================] - 0s 214us/step - loss: 0.0658 - accuracy: 0.9778 - val_loss: 0.6434 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.45271\n",
      "Epoch 487/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.0455 - accuracy: 0.9889 - val_loss: 0.7246 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.45271\n",
      "Epoch 488/500\n",
      "360/360 [==============================] - 0s 278us/step - loss: 0.0591 - accuracy: 0.9861 - val_loss: 0.8189 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.45271\n",
      "Epoch 489/500\n",
      "360/360 [==============================] - 0s 237us/step - loss: 0.0839 - accuracy: 0.9722 - val_loss: 0.8512 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.45271\n",
      "Epoch 490/500\n",
      "360/360 [==============================] - 0s 203us/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.8474 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.45271\n",
      "Epoch 491/500\n",
      "360/360 [==============================] - 0s 249us/step - loss: 0.0571 - accuracy: 0.9861 - val_loss: 0.8433 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.45271\n",
      "Epoch 492/500\n",
      "360/360 [==============================] - 0s 215us/step - loss: 0.0695 - accuracy: 0.9750 - val_loss: 0.8505 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.45271\n",
      "Epoch 493/500\n",
      "360/360 [==============================] - 0s 234us/step - loss: 0.0854 - accuracy: 0.9750 - val_loss: 0.7207 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.45271\n",
      "Epoch 494/500\n",
      "360/360 [==============================] - 0s 201us/step - loss: 0.0939 - accuracy: 0.9750 - val_loss: 0.6630 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.45271\n",
      "Epoch 495/500\n",
      "360/360 [==============================] - 0s 223us/step - loss: 0.0591 - accuracy: 0.9889 - val_loss: 0.5766 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.45271\n",
      "\n",
      "Epoch 00495: ReduceLROnPlateau reducing learning rate to 0.0009492794425459578.\n",
      "Epoch 496/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.0431 - accuracy: 0.9917 - val_loss: 0.5163 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.45271\n",
      "Epoch 497/500\n",
      "360/360 [==============================] - 0s 227us/step - loss: 0.0687 - accuracy: 0.9750 - val_loss: 0.4960 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.45271\n",
      "Epoch 498/500\n",
      "360/360 [==============================] - 0s 208us/step - loss: 0.0639 - accuracy: 0.9833 - val_loss: 0.5078 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.45271\n",
      "Epoch 499/500\n",
      "360/360 [==============================] - 0s 240us/step - loss: 0.0721 - accuracy: 0.9694 - val_loss: 0.5512 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.45271\n",
      "Epoch 500/500\n",
      "360/360 [==============================] - 0s 211us/step - loss: 0.0572 - accuracy: 0.9778 - val_loss: 0.6316 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.45271\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(DATA,LABEL, \n",
    "               batch_size=900,\n",
    "               validation_split=0.1,\n",
    "               callbacks = callbacks_list,\n",
    "               epochs=EPOCHS, \n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('acc_{}_{}_{}.png'.format(EPOCHS, DROPRATE, lossfn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig('loss_{}_{}_{}.png'.format(EPOCHS, DROPRATE, lossfn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
