{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as osp\n",
    "from datetime import datetime\n",
    "import ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import keras.backend as K\n",
    "import keras as keras\n",
    "from keras.models import Sequential,Model\n",
    "# from keras.metrics import mae, categorical_accuracy\n",
    "\n",
    "from keras.layers import MaxPooling1D, Dense, Dropout, Flatten, Input, Conv1D, LeakyReLU, BatchNormalization, Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # curr_path = os.getcwd()\n",
    "# # curr_path\n",
    "# # lossfn = LeakyReLU(alpha=0.02)\n",
    "# optim = 'adam'\n",
    "# lossfn = 'relu'\n",
    "# BATCH = False\n",
    "# EPOCHS = 500\n",
    "# DROPRATE = 0.4\n",
    "# classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dict = {}\n",
    "if classes == 4:\n",
    "    fold_dict = {\"O\":[0, 0,0,1],\"F\":[0, 0,1,0], 'S':[0, 1,0,0], \"N\":[1, 0,0,0]}\n",
    "elif classes == 3:\n",
    "    fold_dict = {\"O\":[0,0,1],\"F\":[0,1,0], 'S':[1,0,0]}\n",
    "# out_len = len(fold_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ID = \"cls:{}_loss:{}_bnm:{}_drop:{}_epo:{}_opt:{}\".format(classes, lossfn, BATCH, DROPRATE, EPOCHS, optim)\n",
    "TEST_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "chk_dir = 'checkpoints'\n",
    "plot_dir = 'plots'\n",
    "logdir = \"logs/scalars/\" + TEST_ID\n",
    "logdir = osp.join(logdir, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "for dirn in [data_dir, chk_dir, plot_dir]:\n",
    "    os.makedirs(dirn, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(fold,label):\n",
    "    fold_arr = []\n",
    "    labels_arr = []\n",
    "    files = []\n",
    "    for f in os.listdir(fold):\n",
    "        files.append(osp.join(fold, f))\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        lines = []\n",
    "        with open(f, 'r') as fw:\n",
    "            for i, line in enumerate(fw):\n",
    "                lines.append(int(line.split()[0]))\n",
    "        lines_arr = np.array(lines)\n",
    "        lines_arr=(lines_arr-np.mean(lines_arr))/np.var(lines_arr)\n",
    "        fold_arr.append(lines_arr)\n",
    "        labels_arr.append(label)\n",
    "    return fold_arr,labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_list = []\n",
    "train_X = []\n",
    "train_Y = []\n",
    "for key,val in fold_dict.items():\n",
    "    x,y = extract(osp.join(data_dir,key),val)\n",
    "    train_X.extend(x)\n",
    "    train_Y.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X),len(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lay = Input((4097,1))\n",
    "\n",
    "\n",
    "l1 = Conv1D(4, kernel_size = 6, strides=1, padding = 'same',activation = lossfn)(in_lay)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(4, kernel_size = 5, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(10, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(10, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(15, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(15, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "    \n",
    "l1 = Conv1D(20, kernel_size = 3, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "flat = Flatten()(ml1)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(50)(flat)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(20)(flat)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(classes)(flat)\n",
    "\n",
    "flat = Softmax()(flat)\n",
    "\n",
    "model=Model(inputs = [in_lay], outputs = [flat])\n",
    "model.compile(optimizer = optim, \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "#                                                                              , mae, categorical_accuracy])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path = osp.join(chk_dir, \n",
    "                       \"{}_{}_weights.best.hdf5\".format('epilepsy', \n",
    "                                                        TEST_ID))\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                   factor=0.998, \n",
    "                                   patience=10, \n",
    "                                   verbose=1, \n",
    "                                   mode='auto', \n",
    "                                   min_delta=0.0001, \n",
    "                                   cooldown=5, \n",
    "                                   min_lr=0.0000001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=150)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat, tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.array(train_X)\n",
    "LABEL = np.array(train_Y)\n",
    "\n",
    "DATA = DATA.reshape((DATA.shape[0], DATA.shape[1], 1))\n",
    "# LABEL = LABEL.reshape((LABEL.shape[0], LABEL.shape[1], 1))\n",
    "\n",
    "# DATA.shape, LABEL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.40585, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009980000474024565.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009960040322039277.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.40585\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.40585 to 1.36649, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.36649 to 1.29813, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.29813 to 1.25529, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.25529 to 1.24113, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.000994011967210099.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.000992023968603462.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.000990039920201525.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.24113\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.24113 to 1.22929, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.22929\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.22929 to 1.22511, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.22511 to 1.22469, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.22469 to 1.22038, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.22038\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.22038\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.22038\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.22038\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.22038 to 1.19609, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.19609 to 1.14584, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.14584 to 1.10663, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.10663 to 1.07856, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 1.07856 to 1.07717, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.07717 to 1.05674, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.05674 to 1.02348, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0009880598220042885.\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.02348\n",
      "\n",
      "Epoch 00108: val_loss improved from 1.02348 to 0.97485, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.97485 to 0.87781, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.87781 to 0.84841, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.84841 to 0.81529, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.81529 to 0.81347, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.000986083674011752.\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.81347\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.81347 to 0.79902, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.79902\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.79902\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.79902\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.79902 to 0.76295, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.76295\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.76295 to 0.75928, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.75928\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.75928\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.75928\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.75928 to 0.70734, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.70734\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.70734 to 0.68912, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.68912 to 0.65218, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.0009841114762239157.\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.65218\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.65218 to 0.64671, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.64671\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.64671\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.64671\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.64671\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.64671 to 0.58663, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.00098214322864078.\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.58663\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.58663 to 0.55563, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 0.000980178931262344.\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.55563\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.55563 to 0.55110, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.55110 to 0.54977, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.54977\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 0.0009782185840886085.\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.54977 to 0.47356, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.47356 to 0.41323, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.41323 to 0.41021, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 0.0009762621871195734.\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 0.0009743096822639927.\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 0.0009723610695218667.\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.41021\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.41021 to 0.40720, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.40720 to 0.40507, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.40507\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.40507 to 0.38574, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.38574 to 0.33106, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.33106 to 0.31726, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 0.0009704163488931954.\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.31726\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.31726 to 0.30939, saving model to checkpoints/epilepsy_cls:4_loss:relu_bnm:False_drop:0.4_epo:500_opt:adam_weights.best.hdf5\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 0.0009684755203779787.\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 0.0009665385839762166.\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 0.0009646054815966636.\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 0.0009626762713305652.\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 0.0009607508950866759.\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 0.0009588294109562412.\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 0.0009569117608480155.\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 0.000954997944761999.\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00416: ReduceLROnPlateau reducing learning rate to 0.0009530879626981914.\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00430: ReduceLROnPlateau reducing learning rate to 0.0009511818146565929.\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.30939\n",
      "\n",
      "Epoch 00444: ReduceLROnPlateau reducing learning rate to 0.0009492794425459578.\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(DATA,LABEL, \n",
    "               batch_size=900,\n",
    "               validation_split=0.1,\n",
    "               callbacks = callbacks_list,\n",
    "               epochs=EPOCHS, \n",
    "               shuffle=True,\n",
    "               verbose=0\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('{}/acc_{}.png'.format(plot_dir, TEST_ID))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig('{}/loss_{}.png'.format(plot_dir, TEST_ID))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_loss'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduceLROnPlat.monitor_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(hist.history['accuracy']), max(hist.history['val_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(hist.history['loss']), min(hist.history['val_loss']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
