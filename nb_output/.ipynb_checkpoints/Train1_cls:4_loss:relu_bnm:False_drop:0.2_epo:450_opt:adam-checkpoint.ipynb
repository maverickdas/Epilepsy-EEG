{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017537,
     "end_time": "2019-11-24T02:49:43.455356",
     "exception": false,
     "start_time": "2019-11-24T02:49:43.437819",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "classes = 4\n",
    "lossfn = \"relu\"\n",
    "BATCH = False\n",
    "EPOCHS = 450\n",
    "DROPRATE = 0.2\n",
    "optim = \"adam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.33714,
     "end_time": "2019-11-24T02:49:43.801347",
     "exception": false,
     "start_time": "2019-11-24T02:49:43.464207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as osp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.003611,
     "end_time": "2019-11-24T02:49:44.814059",
     "exception": false,
     "start_time": "2019-11-24T02:49:43.810448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import keras.backend as K\n",
    "import keras as keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.metrics import mae, categorical_accuracy\n",
    "\n",
    "from keras.layers import MaxPooling1D, Dense, Dropout, Flatten, Input, Conv1D, LeakyReLU, BatchNormalization, Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013507,
     "end_time": "2019-11-24T02:49:44.837010",
     "exception": false,
     "start_time": "2019-11-24T02:49:44.823503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # curr_path = os.getcwd()\n",
    "# # curr_path\n",
    "# # lossfn = LeakyReLU(alpha=0.02)\n",
    "# optim = 'adam'\n",
    "# lossfn = 'relu'\n",
    "# BATCH = False\n",
    "# EPOCHS = 500\n",
    "# DROPRATE = 0.4\n",
    "# classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014259,
     "end_time": "2019-11-24T02:49:44.859297",
     "exception": false,
     "start_time": "2019-11-24T02:49:44.845038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_dict = {}\n",
    "if classes == 4:\n",
    "    fold_dict = {\"O\":[0, 0,0,1],\"F\":[0, 0,1,0], 'S':[0, 1,0,0], \"N\":[1, 0,0,0]}\n",
    "elif classes == 3:\n",
    "    fold_dict = {\"O\":[0,0,1],\"F\":[0,1,0], 'S':[1,0,0]}\n",
    "# out_len = len(fold_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015085,
     "end_time": "2019-11-24T02:49:44.882865",
     "exception": false,
     "start_time": "2019-11-24T02:49:44.867780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cls:4_loss:relu_bnm:False_drop:0.2_epo:450_opt:adam'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ID = \"cls:{}_loss:{}_bnm:{}_drop:{}_epo:{}_opt:{}\".format(classes, lossfn, BATCH, DROPRATE, EPOCHS, optim)\n",
    "TEST_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013281,
     "end_time": "2019-11-24T02:49:44.904533",
     "exception": false,
     "start_time": "2019-11-24T02:49:44.891252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "chk_dir = 'checkpoints'\n",
    "plot_dir = 'plots'\n",
    "logdir = \"logs/scalars/\" + TEST_ID\n",
    "logdir = osp.join(logdir, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01504,
     "end_time": "2019-11-24T02:49:44.927618",
     "exception": false,
     "start_time": "2019-11-24T02:49:44.912578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract(fold,label):\n",
    "    fold_arr = []\n",
    "    labels_arr = []\n",
    "    files = []\n",
    "    for f in os.listdir(fold):\n",
    "        files.append(osp.join(fold, f))\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        lines = []\n",
    "        with open(f, 'r') as fw:\n",
    "            for i, line in enumerate(fw):\n",
    "                lines.append(int(line.split()[0]))\n",
    "        lines_arr = np.array(lines)\n",
    "        lines_arr=(lines_arr-np.mean(lines_arr))/np.var(lines_arr)\n",
    "        fold_arr.append(lines_arr)\n",
    "        labels_arr.append(label)\n",
    "    return fold_arr,labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.711634,
     "end_time": "2019-11-24T02:49:45.648276",
     "exception": false,
     "start_time": "2019-11-24T02:49:44.936642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fin_list = []\n",
    "train_X = []\n",
    "train_Y = []\n",
    "for key,val in fold_dict.items():\n",
    "    x,y = extract(osp.join(data_dir,key),val)\n",
    "    train_X.extend(x)\n",
    "    train_Y.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014045,
     "end_time": "2019-11-24T02:49:45.670488",
     "exception": false,
     "start_time": "2019-11-24T02:49:45.656443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X),len(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.622086,
     "end_time": "2019-11-24T02:49:46.301975",
     "exception": false,
     "start_time": "2019-11-24T02:49:45.679889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_lay = Input((4097,1))\n",
    "\n",
    "\n",
    "l1 = Conv1D(4, kernel_size = 6, strides=1, padding = 'same',activation = lossfn)(in_lay)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(4, kernel_size = 5, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(10, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(10, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(15, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "l1 = Conv1D(15, kernel_size = 4, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "    \n",
    "l1 = Conv1D(20, kernel_size = 3, strides=1, padding = 'same',activation = lossfn)(ml1)\n",
    "ml1 = MaxPooling1D(pool_size=2, strides=2)(l1)\n",
    "if BATCH: ml1 = BatchNormalization()(ml1)\n",
    "\n",
    "flat = Flatten()(ml1)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(50)(flat)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(20)(flat)\n",
    "flat = Dropout(DROPRATE)(flat)\n",
    "\n",
    "flat = Dense(classes)(flat)\n",
    "\n",
    "flat = Softmax()(flat)\n",
    "\n",
    "model=Model(inputs = [in_lay], outputs = [flat])\n",
    "model.compile(optimizer = optim, \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "#                                                                              , mae, categorical_accuracy])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018407,
     "end_time": "2019-11-24T02:49:46.328645",
     "exception": false,
     "start_time": "2019-11-24T02:49:46.310238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path = osp.join(chk_dir, \n",
    "                       \"{}_{}_weights.best.hdf5\".format('epilepsy', \n",
    "                                                        TEST_ID))\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                   factor=0.998, \n",
    "                                   patience=10, \n",
    "                                   verbose=1, \n",
    "                                   mode='auto', \n",
    "                                   min_delta=0.0001, \n",
    "                                   cooldown=5, \n",
    "                                   min_lr=0.0000001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=150)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat, tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.022616,
     "end_time": "2019-11-24T02:49:46.374853",
     "exception": false,
     "start_time": "2019-11-24T02:49:46.352237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA = np.array(train_X)\n",
    "LABEL = np.array(train_Y)\n",
    "\n",
    "DATA = DATA.reshape((DATA.shape[0], DATA.shape[1], 1))\n",
    "# LABEL = LABEL.reshape((LABEL.shape[0], LABEL.shape[1], 1))\n",
    "\n",
    "# DATA.shape, LABEL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2019-11-24T02:49:46.383117",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist=model.fit(DATA,LABEL, \n",
    "               batch_size=900,\n",
    "               validation_split=0.1,\n",
    "               callbacks = callbacks_list,\n",
    "               epochs=EPOCHS, \n",
    "               shuffle=True,\n",
    "               verbose=0\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('{}/acc_{}.png'.format(plot_dir, TEST_ID))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig('{}/loss_{}.png'.format(plot_dir, TEST_ID))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max(hist.history['accuracy']), max(hist.history['val_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(hist.history['loss']), min(hist.history['val_loss']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "Train1.ipynb",
   "output_path": "nb_output/Train1_cls:4_loss:relu_bnm:False_drop:0.2_epo:450_opt:adam.ipynb",
   "parameters": {
    "BATCH": false,
    "DROPRATE": 0.2,
    "EPOCHS": 450,
    "classes": 4,
    "lossfn": "relu",
    "optim": "adam"
   },
   "start_time": "2019-11-24T02:49:42.895474",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}